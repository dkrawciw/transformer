{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f5e0c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import requests\n",
    "import unicodedata\n",
    "\n",
    "from jaxtyping import Int, Float\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55346da0",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e91ce564",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    d_model: int\n",
    "    d_vocab: int\n",
    "    d_hidden: int\n",
    "    n_context: int\n",
    "    n_layers: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2b5d489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Embedding(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "    \n",
    "#     def forward(self):\n",
    "#         pass\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        # self.W_qk = nn.Linear(config.d_model, config.d_vocab)\n",
    "        self.bilinear = nn.Bilinear(config.d_model, config.d_model, config.n_context, bias=False)\n",
    "        self.M = torch.triu(torch.ones((config.n_context, config.n_context)), diagonal=1)\n",
    "        self.M = self.M.masked_fill(self.M.bool(), -torch.inf)\n",
    "        self.second_matmult = nn.Linear(config.d_model, config.d_model, bias=False)\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        xwx = self.bilinear(x, x) # d_m x d_m\n",
    "        x_masked = xwx+ self.M \n",
    "        x_softmaxed = self.softmax(x_masked)\n",
    "        x_fin = x_softmaxed@x\n",
    "        #multiply softmaxed by x\n",
    "        #multiply that by wov\n",
    "        x_fin = self.second_matmult(x_fin)\n",
    "        return x_fin\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.linear_up = nn.Linear(config.d_model, config.d_hidden)\n",
    "        self.linear_down = nn.Linear(config.d_hidden, config.d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_up(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear_down(x)\n",
    "        return x\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.MLP = MLP(config=self.config)\n",
    "        self.Attention = Attention(config=self.config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.Attention(x) + self.MLP(x)\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config:Config):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=config.d_vocab, embedding_dim=config.d_model)\n",
    "        self.transformerBlock = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        for i, l in enumerate(self.transformerBlock):\n",
    "            x = self.transformerBlock[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7ee2d",
   "metadata": {},
   "source": [
    "$n_c$: Context window length\n",
    "\n",
    "$d_m$: Model Dimension\n",
    "\n",
    "$d_v$: Vocab Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "937b0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample = \"The quick brown fox jumped over the lazy dog.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19deb5",
   "metadata": {},
   "source": [
    "# Tokenization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "549c941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_gutenberg_book(\n",
    "\tid: int | None = 84,\n",
    "\tdata_temp: Path | str = \"../data/gutenberg_data\",\n",
    "\tremove_gutenberg_meta: bool = True,\n",
    ") -> str:\n",
    "\t\n",
    "\tdata_temp: Path = Path(data_temp)\n",
    "\tdata_temp.mkdir(parents=True, exist_ok=True)\n",
    "\t\n",
    "\turl: str = f\"https://www.gutenberg.org/cache/epub/{id}/pg{id}.txt\"\n",
    "\tdata_path: Path = Path(data_temp) / f\"{id}.txt\"\n",
    "\tdata: str\n",
    "\t# read from cache if it exists\n",
    "\tif data_path.exists():\n",
    "\t\twith open(data_path, 'r', encoding='utf-8') as file:\n",
    "\t\t\tdata = file.read()\n",
    "\telse:\n",
    "\t\t# download if it doesn't exist\n",
    "\t\tresponse: requests.Response = requests.get(url)\n",
    "\t\tresponse.raise_for_status()  # Ensure that the download was successful\n",
    "\t\tdata = response.text\n",
    "\n",
    "\t\t# save to cache\n",
    "\t\twith open(data_path, 'w', encoding='utf-8') as file:\n",
    "\t\t\tfile.write(data)\n",
    "\n",
    "\t# remove header/footer\n",
    "\tif remove_gutenberg_meta:\n",
    "\t\tdata = '***'.join(data.split('***')[2:])\n",
    "\t\tdata = '***'.join(data.split('***')[:-1])\n",
    "\t\n",
    "\treturn data\n",
    "\n",
    "def get_many_books(\n",
    "\t\tids: list[int],\n",
    "\t\tdata_temp: Path | str = \"../data/gutenberg_data\",\n",
    "\t) -> list[str]:\n",
    "\t\n",
    "\tdata: list[str] = []\n",
    "\tfor id in ids:\n",
    "\t\tprint(f\"Getting book {id}...\")\n",
    "\t\titem: str = get_gutenberg_book(id, data_temp)\n",
    "\t\tprint(f\"\\t{len(item)} characters read\")\n",
    "\t\tdata.append(item)\n",
    "\t\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9c1b9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(\n",
    "\ttext: str,\n",
    "\tallowed_punctuation: str = \"-.,;:!?()\\\"\\\\\" + \"\".join(str(x) for x in range(10)),\n",
    "\tpunctuation_convert: dict[str, str] = {'â€”': '-'},\n",
    ") -> str:\n",
    "\t\n",
    "\t# replace some special characters which unicode won't normalize properly\n",
    "\tfor char, replacement in punctuation_convert.items():\n",
    "\t\ttext = text.replace(char, replacement)\n",
    "\n",
    "\t# if a line has \".jpg\" in it, remove that line (this is specific to Don Quixote)\n",
    "\ttext = '\\n'.join(\n",
    "\t\tline \n",
    "\t\tfor line in text.split('\\n')\n",
    "\t\tif '.jpg' not in line\n",
    "\t)\n",
    "\n",
    "\t# Normalize the string to decompose Unicode characters\n",
    "\ttext = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "\t# Encode to ASCII bytes, then decode back to string, ignoring errors\n",
    "\ttext = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "\t# remove newlines and tabs\n",
    "\ttext = text.replace('\\n', ' ').replace('\\t', ' ')\n",
    "\n",
    "\n",
    "\t# put spaces around allowed punctuation\n",
    "\tfor char in allowed_punctuation:\n",
    "\t\ttext = text.replace(char, f' {char} ')\n",
    "\n",
    "\n",
    "\t# remove leading and trailing spaces\n",
    "\ttext = text.strip()\n",
    "\n",
    "\t# remove multiple spaces\n",
    "\twhile '  ' in text:\n",
    "\t\ttext = text.replace('  ', ' ')\n",
    "\n",
    "\n",
    "\t# remove all characters except (alphanumeric, allowed_punctuation, ' ')\n",
    "\ttext = ''.join(\n",
    "\t\t(\n",
    "\t\t\tchar \n",
    "\t\t\tif (\n",
    "\t\t\t\tchar.isalnum() \n",
    "\t\t\t\tor char in allowed_punctuation \n",
    "\t\t\t\tor char == ' '\n",
    "\t\t\t)\n",
    "\t\t\telse ' '\n",
    "\t\t)\n",
    "\t\tfor char in text \n",
    "\t)\n",
    "\n",
    "\t# convert to lowercase\n",
    "\ttext = text.lower()\n",
    "\n",
    "\ttext = text.strip()\n",
    "\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ad6713ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(\n",
    "\ttext: str,\n",
    "\tprocess: bool = False,\n",
    ") -> list[str]:\n",
    "\tif process:\n",
    "\t\ttext = process_text(text)\n",
    "\treturn text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7c274f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting book 6762...\n",
      "\t584611 characters read\n",
      "Getting book 1497...\n",
      "\t1219052 characters read\n",
      "Getting book 8438...\n",
      "\t648768 characters read\n",
      "Getting book 1600...\n",
      "\t181248 characters read\n",
      "Getting book 1656...\n",
      "\t87284 characters read\n"
     ]
    }
   ],
   "source": [
    "# Getting books from Plato and Aristotle\n",
    "DATA_RAW: list[str] = get_many_books([6762, 1497, 8438, 1600, 1656])\n",
    "DATA: str = \" \".join(process_text(x) for x in DATA_RAW)\n",
    "DATA_TOKENIZED: list[str] = tokenize(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "317fb7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ENCODED = array([1181,   25, 9326, ..., 4819, 4354, 1842], shape=(556819,))\n",
      "556819\n"
     ]
    }
   ],
   "source": [
    "# sorted by frequency\n",
    "VOCAB_FREQ: Counter[str] = Counter(DATA_TOKENIZED)\n",
    "VOCAB_ARR: list[str] = [word for word, _ in VOCAB_FREQ.most_common()]\n",
    "VOCAB_DICT: dict[str, int] = {word: i for i, word in enumerate(VOCAB_ARR)}\n",
    "\n",
    "def encode(\n",
    "\ttext: str | list[str],\n",
    ") -> Int[np.ndarray, \" n_tokens\"]:\n",
    "\tif isinstance(text, str):\n",
    "\t\ttext = tokenize(text)\n",
    "\treturn np.array([VOCAB_DICT[word] for word in text])\n",
    "\n",
    "def decode(\n",
    "\tencoded_text: Int[np.ndarray, \" n_tokens\"] | list[int],\n",
    ") -> str:\n",
    "\treturn ' '.join(VOCAB_ARR[i] for i in encoded_text)\n",
    "\n",
    "DATA_ENCODED: Int[np.ndarray, \" n_tokens\"] = encode(DATA)\n",
    "\n",
    "print(f\"{DATA_ENCODED = }\")\n",
    "print(len(DATA_ENCODED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e469a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.input = x[:-1]\n",
    "        self.output = x[1:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.input[idx]\n",
    "        out = self.output[idx]\n",
    "        return inp, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38824d3",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a7248308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "tensor([[ 2.4382e-01, -3.3684e-01,  4.2113e-01,  2.5118e-01, -7.0882e-02,\n",
      "         -1.2463e-01, -1.5439e-01,  1.8969e-01,  5.7837e-02,  2.6203e-01],\n",
      "        [-2.0029e-01, -4.6962e-01,  5.1820e-01,  6.3898e-01,  7.1709e-01,\n",
      "         -5.3796e-01, -6.4178e-04, -3.2100e-01,  7.9542e-01,  1.3639e-01],\n",
      "        [-2.0988e-01, -8.1415e-01,  4.3507e-01,  5.6735e-02,  7.1053e-01,\n",
      "         -8.0142e-01, -8.2580e-02, -8.2268e-01,  5.1185e-03,  1.4978e-01],\n",
      "        [-2.6728e-02, -4.0513e-01,  5.8866e-01,  3.4510e-01,  5.5723e-01,\n",
      "         -6.4959e-01, -6.8502e-02, -5.3238e-01,  4.3269e-01,  3.8217e-01],\n",
      "        [ 3.5831e-01, -1.9775e-01,  1.9581e-01, -4.9297e-02, -1.9818e-01,\n",
      "         -1.5570e-01, -1.8320e-01,  1.2315e-01,  1.5451e-02,  6.1414e-02]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "d_model = 10\n",
    "d_vocab = 10\n",
    "d_hidden = 10\n",
    "n_context = 5\n",
    "n_layers = 10\n",
    "\n",
    "x = torch.randn((n_context, d_model))\n",
    "\n",
    "conf = Config(d_model, d_vocab, d_hidden, n_context, n_layers)\n",
    "mlp = MLP(conf)\n",
    "attention = Attention(conf)\n",
    "Aoutput = attention(x)\n",
    "print(Aoutput.shape)\n",
    "\n",
    "output = mlp(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6758f832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7564, -0.1901, -0.8199, -0.7058, -0.1407, -3.1887, -0.8120,  0.6575,\n",
       "         -0.8009,  0.5691],\n",
       "        [ 1.7548,  0.1369,  0.5451, -1.0349,  0.2123, -1.7916, -0.3687, -0.1708,\n",
       "         -1.4231, -0.3296],\n",
       "        [ 0.3693,  0.3610, -0.3178, -2.5366,  2.2737,  2.9342,  4.3649,  1.5633,\n",
       "         -1.1154, -1.4197],\n",
       "        [-1.0282,  0.9102,  1.1436,  0.5715,  0.6032, -1.1302, -0.1641, -0.2860,\n",
       "         -0.4190,  0.8458],\n",
       "        [ 0.0359, -0.4625,  2.2205, -0.5128,  0.5866, -0.4680, -1.0618,  0.2394,\n",
       "          0.1510,  1.5151]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer Block test\n",
    "\n",
    "d_model = 10\n",
    "d_vocab = len(VOCAB_DICT)\n",
    "d_hidden = 10\n",
    "n_context = 5\n",
    "n_layers = 10\n",
    "\n",
    "config = Config(\n",
    "    d_model = d_model,\n",
    "    d_vocab = d_vocab,\n",
    "    d_hidden = d_hidden,\n",
    "    n_context = n_context,\n",
    "    n_layers = n_layers,\n",
    ")\n",
    "\n",
    "x = torch.randn((n_context, d_model))\n",
    "conf = Config(d_model, d_vocab, d_hidden, n_context, n_layers)\n",
    "\n",
    "tb = TransformerBlock(config)\n",
    "\n",
    "output_x = tb(x)\n",
    "output_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222519f",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Config(d_model = 10, \n",
    "              d_vocab = len(VOCAB_DICT), \n",
    "              d_hidden = 10, \n",
    "              n_context = 10, \n",
    "              n_layers = 2\n",
    "              )\n",
    "\n",
    "training_data = torch.utils.data.TensorDataset(torch.from_numpy(DATA_ENCODED[:-1]),torch.from_numpy(DATA_ENCODED[1:]))\n",
    "model = Transformer(config=conf)\n",
    "training_loader = torch.utils.data.DataLoader(training_data, batch_size=4, shuffle=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b37051bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c9356405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[188]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[32m     17\u001b[39m model.train(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m avg_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m running_vloss = \u001b[32m0.0\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# statistics for batch normalization.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[184]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(epoch_index, tb_writer)\u001b[39m\n\u001b[32m     13\u001b[39m optimizer.zero_grad()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Make predictions for this batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Compute the loss and its gradients\u001b[39;00m\n\u001b[32m     19\u001b[39m loss = loss_fn(outputs, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shane\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shane\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     58\u001b[39m x = \u001b[38;5;28mself\u001b[39m.embedding(x)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.transformerBlock):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformerBlock\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shane\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shane\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.MLP(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shane\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shane\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     19\u001b[39m     xwx = \u001b[38;5;28mself\u001b[39m.bilinear(x, x) \u001b[38;5;66;03m# d_m x d_m\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     x_masked = \u001b[43mxwx\u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mM\u001b[49m \n\u001b[32m     21\u001b[39m     x_softmaxed = \u001b[38;5;28mself\u001b[39m.softmax(x_masked)\n\u001b[32m     22\u001b[39m     x_fin = x_softmaxed\u001b[38;5;129m@x\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
